{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import math\n",
    "import numpy as np\n",
    "import inspect\n",
    "import os\n",
    "import time\n",
    "from IPython.display import Image, display, HTML\n",
    "import importlib\n",
    "import socket\n",
    "import argparse\n",
    "\n",
    "# working dir\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# name of this script\n",
    "scriptname = inspect.getframeinfo(inspect.currentframe()).filename\n",
    "scriptpath = os.path.dirname(os.path.abspath(scriptname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook generate-oomph.ipynb to script\n",
      "[NbConvertApp] Writing 13176 bytes to generate-oomph.py\n"
     ]
    }
   ],
   "source": [
    "def is_notebook():\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter\n",
    "\n",
    "if is_notebook():\n",
    "    # this makes the notebook wider on a larger screen using %x of the display\n",
    "    display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "    # save this notebook as a raw python file as well please\n",
    "    get_ipython().system('jupyter nbconvert --to script generate-oomph.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Command line params\n",
    "# ------------------------------------------------------------------\n",
    "def get_command_line_args(notebook_args=None):\n",
    "    parser = argparse.ArgumentParser(description='Generator for oomph benchmarks')\n",
    "    parser.add_argument('-d', '--dir', default=cwd, action='store', help='base directory to generate job scripts in')\n",
    "    parser.add_argument('-t', '--type', default='normal', action='store', help='normal, timed or native for different test types')\n",
    "    parser.add_argument('-T', '--timeout', default=120, action='store', help='executable timeout period')\n",
    "    parser.add_argument('-m', '--machine', default='', action='store', help='select machine batch job config/preamble')\n",
    "    if is_notebook():\n",
    "        parser.add_argument('-f', help='seems to be defaulted by jupyter')\n",
    "        return parser.parse_args(notebook_args)\n",
    "    return parser.parse_args()\n",
    "\n",
    "notebook_args = '--type=native --dir /home/biddisco/benchmarking-results/test'.split()\n",
    "if is_notebook():\n",
    "    args = get_command_line_args(notebook_args)\n",
    "else:\n",
    "    args = get_command_line_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD        : /home/biddisco/src/ghex/extern/oomph/benchmarks/scripts \n",
      "Scriptpath : /tmp/ipykernel_91426 \n",
      "Hostname   : oryx2\n"
     ]
    }
   ],
   "source": [
    "# hostname + cleanup login node 'daint101' etc\n",
    "if args.machine != '':\n",
    "    hostname = args.machine\n",
    "elif os.environ.get('LUMI_STACK_NAME', 'oryx2') == 'LUMI':\n",
    "    hostname = 'lumi'\n",
    "elif socket.gethostname().startswith('daint'):\n",
    "    hostname = 'daint'\n",
    "else :\n",
    "    hostname = 'oryx2'\n",
    "\n",
    "# summary\n",
    "print(f'CWD        : {cwd} \\nScriptpath : {scriptpath} \\nHostname   : {hostname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_executable(path):\n",
    "    mode = os.stat(path).st_mode\n",
    "    mode |= (mode & 0o444) >> 2    # copy R bits to X\n",
    "    os.chmod(path, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating scripts in /home/biddisco/benchmarking-results/test\n"
     ]
    }
   ],
   "source": [
    "# strings with @xxx@ will be substituted by cmake\n",
    "binary_dir = \"@BIN_DIR@\"\n",
    "\n",
    "if args.dir:\n",
    "    run_dir = args.dir\n",
    "else:\n",
    "    run_dir = \"@RUN_DIR@\"\n",
    "\n",
    "print(f'Generating scripts in {run_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cscs = {}\n",
    "\n",
    "# jb laptop\n",
    "cscs[\"oryx2\"] = {\n",
    "  \"Machine\":\"system76\",\n",
    "  \"Cores\": 8,\n",
    "  \"Threads per core\": 2,\n",
    "  \"Allowed rpns\": [1, 2],\n",
    "  \"Thread_array\": [1,2,4],\n",
    "  \"Sleeptime\":0,\n",
    "  \"Launch\": \"pushd {job_path} && source {job_file} && popd\",\n",
    "  \"Run command\": \"mpiexec -n {total_ranks} --oversubscribe timeout {timeout} \",\n",
    "  \"Batch preamble\": \"\"\"\n",
    "#!/bin/bash -l\n",
    "\n",
    "# Env\n",
    "#export OMP_NUM_THREADS={threads}\n",
    "#export GOMP_CPU_AFFINITY=0-{threadsm1}\n",
    "\n",
    "# Commands\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "# daint mc nodes config\n",
    "cscs[\"daint\"] = {\n",
    "  \"Machine\":\"daint\",\n",
    "  \"Cores\": 128,\n",
    "  \"Threads per core\": 2,\n",
    "  \"Allowed rpns\": [1],\n",
    "  \"Thread_array\": [1,2,4,8,16],\n",
    "  \"Sleeptime\":0.25,\n",
    "  \"Launch\": \"sbatch --chdir={job_path} {job_file}\",\n",
    "  \"Run command\": \"srun --cpu-bind=cores --unbuffered --ntasks {total_ranks} --cpus-per-task {threads_per_rank} timeout {timeout} \",\n",
    "  \"Batch preamble\": \"\"\"\n",
    "#!/bin/bash -l\n",
    "#SBATCH --job-name={run_name}_{transport}_{nodes}_{threads}_{inflight}_{size}\n",
    "#SBATCH --time={time_min}\n",
    "#SBATCH --nodes={nodes}\n",
    "#SBATCH --partition=normal\n",
    "#SBATCH --account=csstaff\n",
    "#SBATCH --constraint=mc\n",
    "#SBATCH --output=output.txt\n",
    "#SBATCH --error=error.txt\n",
    "\n",
    "module swap craype/2.7.10 craype/2.7.15\n",
    "\n",
    "# alternatives : srun --cpu-bind v,mask_cpu:0xffff\n",
    "# export GOMP_CPU_AFFINITY=0-{threadsm1}\n",
    "\n",
    "# Old Env vars that might be useful\n",
    "# export MPICH_MAX_THREAD_SAFETY=multiple\n",
    "# export OMP_NUM_THREADS={threads}\n",
    "# export MKL_NUM_THREADS={threads}\n",
    "# export MPICH_GNI_NDREG_ENTRIES=1024\n",
    "\n",
    "# Debug\n",
    "module list &> modules.txt\n",
    "printenv > env.txt\n",
    "\n",
    "# Commands\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "# daint mc nodes config\n",
    "cscs[\"lumi\"] = {\n",
    "  \"Machine\":\"lumi\",\n",
    "  \"Cores\": 16,\n",
    "  \"Threads per core\": 2,\n",
    "  \"Allowed rpns\": [1],\n",
    "  \"Thread_array\": [1,2,4,8,16],\n",
    "  \"Sleeptime\":0.25,\n",
    "  \"Launch\": \"sbatch --chdir={job_path} {job_file}\",\n",
    "  \"Run command\": \"srun --cpu-bind=cores --unbuffered --ntasks {total_ranks} --cpus-per-task {threads_per_rank} timeout {timeout} \",\n",
    "  \"Batch preamble\": \"\"\"\n",
    "#!/bin/bash -l\n",
    "#SBATCH --job-name={run_name}_{transport}_{nodes}_{threads}_{inflight}_{size}\n",
    "#SBATCH --time={time_min}\n",
    "#SBATCH --nodes={nodes}\n",
    "#SBATCH --partition=standard\n",
    "#SBATCH --account=project_465000105\n",
    "#SBATCH --output=output.txt\n",
    "#SBATCH --error=error.txt\n",
    "\n",
    "module load LUMI/22.06\n",
    "module load cpeGNU\n",
    "module load buildtools\n",
    "module load Boost\n",
    "\n",
    "# alternatives : srun --cpu-bind v,mask_cpu:0xffff\n",
    "# export GOMP_CPU_AFFINITY=0-{threadsm1}\n",
    "\n",
    "export MPICH_MAX_THREAD_SAFETY=multiple\n",
    "# export OMP_NUM_THREADS={threads}\n",
    "# export MKL_NUM_THREADS={threads}\n",
    "# export MPICH_GNI_NDREG_ENTRIES=1024\n",
    "\n",
    "# Debug\n",
    "module list &> modules.txt\n",
    "printenv > env.txt\n",
    "\n",
    "# Commands\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "\n",
    "cscs['eiger'] = cscs['daint']\n",
    "cscs['eiger']['Machine'] = 'eiger'\n",
    "cscs['eiger']['Cores'] = 64\n",
    "cscs['eiger']['Thread_array'] = [1,2,4,8,16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Generate Job script preamble\n",
    "#\n",
    "def init_job_text(system, run_name, time_min, transport, nodes, threads, inflight, size):\n",
    "    return system[\"Batch preamble\"].format(run_name=run_name,\n",
    "                                           time_min=time_min,\n",
    "                                           transport=transport,\n",
    "                                           nodes=nodes,\n",
    "                                           threads=threads,\n",
    "                                           threadsm1=(threads-1),\n",
    "                                           inflight=inflight,\n",
    "                                           size=size).strip()\n",
    "#\n",
    "# create a directory name from params\n",
    "#\n",
    "def make_job_directory(fdir,name, transport, nodes, threads, inflight, size):\n",
    "    return f'{fdir}/{name}_{transport}_{nodes}_{threads}_{inflight}_{size}'\n",
    "\n",
    "#\n",
    "# create the launch command-line\n",
    "#\n",
    "def run_command(system, total_ranks, cpus_per_rank, timeout):\n",
    "    return system[\"Run command\"].format(total_ranks=total_ranks, cpus_per_rank=cpus_per_rank, threads_per_rank=cpus_per_rank, timeout=timeout)\n",
    "\n",
    "#\n",
    "# create dir + write final script for sbatch/shell or other job launcher\n",
    "#\n",
    "def write_job_file(system, launch_file, job_dir, job_text, suffix=''):\n",
    "    job_path = os.path.expanduser(job_dir)\n",
    "    os.makedirs(job_path, exist_ok=True)\n",
    "    job_file = f\"{job_path}/job_{suffix}.sh\"\n",
    "    print(f\"Generating : {job_path} : {job_file}\")\n",
    "\n",
    "    with open(job_file, \"w\") as f:\n",
    "        f.write(job_text)\n",
    "        make_executable(job_file)\n",
    "\n",
    "    launchstring  = system[\"Launch\"].format(job_path=job_path,job_file=job_file) + '\\n'\n",
    "    launchstring += 'sleep ' + str(system['Sleeptime']) + '\\n'\n",
    "    launch_file.write(launchstring)\n",
    "\n",
    "#\n",
    "# generate a string that decorates and launches a single instance of the test\n",
    "#\n",
    "def execution_string(env, launch_cmd, prog_cmd, output_redirect):\n",
    "    full_command = f\"{env} {launch_cmd} {prog_cmd}\".strip()\n",
    "    command_prologue  = f'printf \"\\\\n'\n",
    "    command_prologue += f'# ----- Executing \\\\n'\n",
    "    command_prologue += f'{full_command}    \\\\n'\n",
    "    command_prologue += f'# --------------- \\\\n\" >> {output_redirect}'\n",
    "    command_epilogue  = f'printf \"\\\\n'\n",
    "    command_epilogue += f'# ----- Finished  \\\\n\\\\n\" >> {output_redirect}'\n",
    "    return '\\n' + command_prologue + '\\n' + full_command + ' >> ' + output_redirect + '\\n' + command_epilogue + '\\n'\n",
    "\n",
    "#\n",
    "# generate application specific commmands/flags/options that go into the job script\n",
    "#\n",
    "def oomph_original(system, bin_dir, timeout, transport, progs, nodes, threads, msg, size, inflight, env):\n",
    "    total_ranks = 2\n",
    "    whole_cmd = ''\n",
    "    suffix = ''\n",
    "\n",
    "    # transport layers use '_libfabric', '_ucx', '_mpi', etc\n",
    "    if args.type!='native':\n",
    "        suffix = f'_{transport}'\n",
    "\n",
    "    # timed version uses seconds instead of messages/iterations\n",
    "    if args.type=='timed':\n",
    "        msg = 30\n",
    "\n",
    "    # always remember to add a space to the end of each env var for concatenation of many of them\n",
    "    if threads==1:\n",
    "        env +=  'MPICH_MAX_THREAD_SAFETY=single '\n",
    "    else:\n",
    "        env +=  'MPICH_MAX_THREAD_SAFETY=multiple '\n",
    "        env += f'OMP_NUM_THREADS={threads} '\n",
    "        env += f'GOMP_CPU_AFFINITY=0-{threads} '\n",
    "\n",
    "    for prog in progs:\n",
    "        if threads>1:\n",
    "            if args.type=='normal' or args.type=='timed':\n",
    "                prog = prog + '_mt'\n",
    "\n",
    "        if transport=='native' and threads==1:\n",
    "            prog = prog.replace('_mt_','_')\n",
    "\n",
    "        # generate the name of the output file we redirect output to\n",
    "        outfile = f'{prog}_N{nodes}_T{threads}_I{msg}_S{size}_F{inflight}.out'\n",
    "\n",
    "        # generate the program commmand with all command line params needed by program\n",
    "        prog_cmd = f\"{bin_dir}/{prog}{suffix} {msg} {size} {inflight}\"\n",
    "\n",
    "        # get the system launch command (mpiexec, srun, etc) with options/params\n",
    "        launch_cmd = run_command(system, total_ranks, threads, timeout)\n",
    "\n",
    "        if transport=='libfabric':\n",
    "            env2 = env + 'LIBFABRIC_POLL_SIZE=32 '\n",
    "            #for ep in ['single', 'multiple', 'scalableTx', 'threadlocal']:\n",
    "            for ep in ['threadlocal']:\n",
    "                whole_cmd += execution_string(env2 + f\"LIBFABRIC_ENDPOINT_TYPE={ep} \", launch_cmd, prog_cmd, outfile)\n",
    "            if False: # add option to enable this?\n",
    "                whole_cmd += execution_string(env2 + f\"LIBFABRIC_ENDPOINT_TYPE={ep} \" + f\"LIBFABRIC_AUTO_PROGRESS=1 \", launch_cmd, prog_cmd, outfile)\n",
    "        else:\n",
    "            whole_cmd += execution_string(env, launch_cmd, prog_cmd, outfile)\n",
    "\n",
    "    return whole_cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = cscs[hostname]\n",
    "#\n",
    "job_name       = 'oomph'\n",
    "timeout        = args.timeout\n",
    "time_min       = 2000*60 # total time estimate\n",
    "timestr        = time.strftime('%H:%M:%S', time.gmtime(time_min))\n",
    "ranks_per_node = 1\n",
    "nodes_arr = [2]\n",
    "thrd_arr  = system['Thread_array']\n",
    "size_arr  = [1,10,100,1000, 2000, 5000, 10000, 20000, 50000, 100000, 200000, 500000, 1000000, 2000000]\n",
    "nmsg_lut  = {1:500000,\n",
    "             10:500000,\n",
    "             100:500000,\n",
    "             1000:500000,\n",
    "             2000:500000,\n",
    "             5000:250000,\n",
    "             10000:250000,\n",
    "             20000:250000,\n",
    "             50000:250000,\n",
    "             100000:250000,\n",
    "             200000:250000,\n",
    "             500000:100000,\n",
    "             1000000:50000,\n",
    "             2000000:25000}\n",
    "\n",
    "flight_arr = [1,10,50,100]\n",
    "\n",
    "if args.type=='normal':\n",
    "    trans_arr = ['libfabric', 'mpi']\n",
    "    prog_arr  = [\n",
    "        #\"bench_p2p_bi_cb_avail\",\n",
    "        #\"bench_p2p_bi_cb_wait\",\n",
    "        \"bench_p2p_bi_ft_avail\",\n",
    "        #\"bench_p2p_bi_ft_wait\"\n",
    "    ]\n",
    "\n",
    "if args.type=='timed':\n",
    "    trans_arr = ['libfabric', 'mpi']\n",
    "    prog_arr  = ['bench_p2p_pp_ft_avail']\n",
    "\n",
    "if args.type=='native':\n",
    "    trans_arr = ['native']\n",
    "    prog_arr  = [\n",
    "        #\"mpi_p2p_bi_avail_mt_test\", \"mpi_p2p_bi_avail_mt_testany\",\n",
    "        #\"mpi_p2p_bi_wait_mt_wait\",\n",
    "        \"mpi_p2p_bi_wait_mt_waitall\"\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncommment the following line to perform the job creation\n",
      "Generating : /home/biddisco/benchmarking-results/test/oomph_all_2_1_1_1 : /home/biddisco/benchmarking-results/test/oomph_all_2_1_1_1/job_.sh\n",
      "Combinations 168 est-time 1344 minutes\n"
     ]
    }
   ],
   "source": [
    "combos = 0\n",
    "\n",
    "if run_dir.startswith('@'):\n",
    "    print(f'Skipping creation of job launch file for {run_dir}')\n",
    "else:\n",
    "    job_launch = f\"{run_dir}/launch.sh\"\n",
    "    job_launch_file = open(job_launch, \"w\")\n",
    "    #\n",
    "    job_launch_file.write(\"#!/bin/bash -l\\n\")\n",
    "\n",
    "# create the output directory for each job\n",
    "job_dir = make_job_directory(run_dir, 'oomph', \"all\", 2, 1, 1, 1)\n",
    "\n",
    "# first part of boiler plate job script\n",
    "job_text = init_job_text(system, job_name, timestr, \"all\", 2, 16, 1, 1)\n",
    "\n",
    "# generate all combinations in one monster loop\n",
    "for nodes, transport, threads, size, inflight in product(nodes_arr, trans_arr, thrd_arr, size_arr, flight_arr):\n",
    "\n",
    "    env = \"\"\n",
    "    msg = nmsg_lut[size]\n",
    "\n",
    "    # create the output directory for each job\n",
    "    #job_dir = make_job_directory(run_dir, 'oomph', transport, nodes, threads, inflight, size)\n",
    "\n",
    "    # first part of boiler plate job script\n",
    "    #job_text = init_job_text(system, job_name, timestr, transport, nodes, threads, inflight, size)\n",
    "\n",
    "    env = 'MPICH_GNI_NDREG_ENTRIES=1024 '\n",
    "\n",
    "    # application specific part of job script\n",
    "    job_text += oomph_original(\n",
    "        system,\n",
    "        binary_dir,\n",
    "        timeout,\n",
    "        transport,\n",
    "        prog_arr,\n",
    "        nodes,\n",
    "        threads,\n",
    "        msg,\n",
    "        size,\n",
    "        inflight,\n",
    "        env\n",
    "    )\n",
    "    # debugging\n",
    "    # print(job_dir, '\\n', job_text, '\\n\\n\\n\\n')\n",
    "\n",
    "    combos += 1\n",
    "\n",
    "    if combos==1:\n",
    "        print('Uncommment the following line to perform the job creation')\n",
    "\n",
    "write_job_file(system, job_launch_file, job_dir, job_text)\n",
    "\n",
    "make_executable(job_launch)\n",
    "print('Combinations', combos, 'est-time', combos*4*2,'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
